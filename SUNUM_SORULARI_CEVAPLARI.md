# SUNUM Ä°Ã‡Ä°N HAZIRLIK: SORULAR VE CEVAPLAR

## ğŸ“‹ PROJE GENELÄ° HAKKINDA SORULAR

### S1: Projenizin amacÄ± nedir?
**Cevap:**
- 22 farklÄ± egzersiz tÃ¼rÃ¼nÃ¼ video ve gÃ¶rsellerden otomatik olarak sÄ±nÄ±flandÄ±rmak
- MediaPipe pose detection ile vÃ¼cut pozisyonlarÄ±nÄ± tespit etmek
- Derin Ã¶ÄŸrenme modelleri ile egzersiz tanÄ±ma yapmak
- KiÅŸisel antrenÃ¶r uygulamalarÄ± iÃ§in otomatik form analizi saÄŸlamak

### S2: Neden bu projeyi seÃ§tiniz?
**Cevap:**
- Spor ve saÄŸlÄ±k alanÄ±nda pratik bir uygulama
- Computer vision ve deep learning teknolojilerini birleÅŸtirme fÄ±rsatÄ±
- GerÃ§ek dÃ¼nya problemine Ã§Ã¶zÃ¼m (egzersiz form kontrolÃ¼)
- AÃ§Ä±k kaynak veri seti kullanÄ±labilirliÄŸi

### S3: Projenin en bÃ¼yÃ¼k zorluklarÄ± nelerdi?
**Cevap:**
- 22 farklÄ± egzersiz sÄ±nÄ±fÄ±nÄ± ayÄ±rt etmek (bazÄ±larÄ± birbirine benzer)
- Veri seti hazÄ±rlama ve keypoints Ã§Ä±karma sÃ¼recinin zaman almasÄ±
- Ä°ki farklÄ± model tipini (gÃ¶rsel + video) koordine etmek
- MediaPipe ile Windows uyumluluÄŸu sorunlarÄ±
- Train/test split'te veri leakage Ã¶nleme

---

## ğŸ”§ TEKNOLOJÄ°LER HAKKINDA SORULAR

### S4: Neden MediaPipe kullandÄ±nÄ±z?
**Cevap:**
- Google'Ä±n aÃ§Ä±k kaynak, Ã¼cretsiz pose detection kÃ¼tÃ¼phanesi
- 33 vÃ¼cut landmark noktasÄ± tespiti (yÃ¼ksek doÄŸruluk)
- CPU'da Ã§alÄ±ÅŸabilir (GPU gerektirmez)
- Kolay entegrasyon ve kullanÄ±m
- GerÃ§ek zamanlÄ± iÅŸleme desteÄŸi

### S5: Neden PyTorch seÃ§tiniz, TensorFlow deÄŸil?
**Cevap:**
- Daha esnek ve Pythonic API
- Dynamic computation graph (LSTM iÃ§in avantajlÄ±)
- CUDA desteÄŸi ile GPU hÄ±zlandÄ±rma
- Aktif topluluk ve dokÃ¼mantasyon
- EÄŸitim sÄ±rasÄ±nda daha kolay debug

### S6: Ä°ki farklÄ± model (Image ve Sequence) neden kullandÄ±nÄ±z?
**Cevap:**
- **Image Classifier (MLP)**: Statik pozlarÄ± Ã¶ÄŸrenir, hÄ±zlÄ± eÄŸitim
- **Sequence Classifier (LSTM)**: Zaman serisi bilgisini kullanÄ±r, hareket akÄ±ÅŸÄ±nÄ± Ã¶ÄŸrenir
- Hibrit yaklaÅŸÄ±m: Her iki veri tipinden de Ã¶ÄŸrenme
- GerÃ§ek dÃ¼nyada video kullanÄ±ldÄ±ÄŸÄ± iÃ§in Sequence Model daha uygun
- Image Model eÄŸitim verisi artÄ±rmak iÃ§in kullanÄ±ldÄ±

### S7: Neden LSTM kullandÄ±nÄ±z, Transformer deÄŸil?
**Cevap:**
- LSTM daha az parametre gerektirir (daha hÄ±zlÄ± eÄŸitim)
- Sequence length (60 frame) iÃ§in yeterli
- Transformer daha fazla veri gerektirir
- LSTM video sequence'leri iÃ§in klasik ve etkili Ã§Ã¶zÃ¼m
- Proje kapsamÄ±na uygun (basit ama etkili)

### S8: OpenCV'nin rolÃ¼ nedir?
**Cevap:**
- Video okuma ve yazma (cv2.VideoCapture)
- GÃ¶rsel okuma (cv2.imread)
- Frame iÅŸleme
- Video Ã¶zelliklerini alma (FPS, boyut, frame sayÄ±sÄ±)
- MediaPipe ile entegrasyon iÃ§in gerekli

---

## ğŸ“Š VERÄ° Ä°ÅLEME HAKKINDA SORULAR

### S9: Veri setinizi nereden aldÄ±nÄ±z?
**Cevap:**
- Kaggle'dan aÃ§Ä±k kaynak egzersiz video veri seti
- 22 farklÄ± egzersiz tÃ¼rÃ¼
- Her egzersiz iÃ§in Ã§ok sayÄ±da video
- AÃ§Ä±k lisanslÄ±, akademik kullanÄ±m iÃ§in uygun

### S10: Train/test split oranÄ±nÄ±z nedir ve neden?
**Cevap:**
- %70 train, %30 test
- Standart makine Ã¶ÄŸrenmesi pratiÄŸi
- Yeterli eÄŸitim verisi saÄŸlar
- Test seti iÃ§in yeterli Ã¶rnek
- Random seed (42) ile tekrarlanabilir

### S11: Neden train'de hem gÃ¶rseller hem videolar var, test'te sadece videolar?
**Cevap:**
- **Train'de**: Ä°ki model iÃ§in veri (Image + Sequence)
- **Test'te**: GerÃ§ek dÃ¼nya senaryosu (kullanÄ±cÄ± video yÃ¼kler)
- Veri leakage Ã¶nleme (test videolarÄ±ndan gÃ¶rsel Ã§Ä±karÄ±lmadÄ±)
- Train'de daha fazla veri = daha iyi Ã¶ÄŸrenme
- Test gerÃ§ekÃ§i kalÄ±r

### S12: Keypoints Ã§Ä±karma iÅŸlemi nasÄ±l Ã§alÄ±ÅŸÄ±yor?
**Cevap:**
- MediaPipe her frame'de 33 vÃ¼cut landmark noktasÄ± tespit eder
- Her landmark iÃ§in: x, y, z koordinatlarÄ± + visibility skoru
- Toplam: 33 Ã— 4 = 132 boyut
- Koordinatlar 0-1 arasÄ± normalize (gÃ¶rÃ¼ntÃ¼ boyutuna gÃ¶re)
- `pose_detector.py` dosyasÄ±nda `extract_keypoints()` fonksiyonu

### S13: Veri Ã¶n iÅŸleme yaptÄ±nÄ±z mÄ±?
**Cevap:**
- âœ… Keypoints normalizasyonu (MediaPipe otomatik yapÄ±yor)
- âœ… Label encoding (egzersiz isimleri â†’ sayÄ±sal etiketler)
- âœ… Train/validation split (%80/%20)
- âœ… Sequence padding (kÄ±sa videolar iÃ§in)
- âœ… Sliding window (uzun videolarÄ± 60 frame'lik sequence'lere bÃ¶lme)
- âŒ Veri arttÄ±rma yapÄ±lmadÄ± (gelecek geliÅŸtirme)

### S14: Neden veri arttÄ±rma yapmadÄ±nÄ±z?
**Cevap:**
- MediaPipe keypoints zaten normalize ve robust
- Keypoints Ã¼zerinde rotation/scale augmentation zor
- Yeterli veri seti mevcut
- Gelecek geliÅŸtirme olarak eklenebilir
- Ã–ncelik model mimarisi ve eÄŸitim sÃ¼recine verildi

---

## ğŸ—ï¸ MODEL MÄ°MARÄ°SÄ° HAKKINDA SORULAR

### S15: Image Classifier mimarisini aÃ§Ä±klar mÄ±sÄ±nÄ±z?
**Cevap:**
- **Tip**: MLP (Multi-Layer Perceptron)
- **Girdi**: (batch_size, 132) - Tek frame keypoints
- **Katmanlar**:
  - Input: 132
  - Hidden 1: 256 + ReLU + Dropout(0.3)
  - Hidden 2: 128 + ReLU + Dropout(0.3)
  - Hidden 3: 64 + ReLU + Dropout(0.3)
  - Output: 22 (egzersiz sÄ±nÄ±flarÄ±)
- **Parametre sayÄ±sÄ±**: ~100K
- **KullanÄ±m**: Statik pozlardan egzersiz tanÄ±ma

### S16: Sequence Classifier mimarisini aÃ§Ä±klar mÄ±sÄ±nÄ±z?
**Cevap:**
- **Tip**: LSTM (Long Short-Term Memory)
- **Girdi**: (batch_size, 60, 132) - 60 frame'lik sequence
- **Katmanlar**:
  - LSTM Layer 1: 128 hidden units, 2 layers
  - Dropout(0.3)
  - Dense: 64 + ReLU
  - Dropout(0.3)
  - Output: 22 (egzersiz sÄ±nÄ±flarÄ±)
- **Parametre sayÄ±sÄ±**: ~200K
- **KullanÄ±m**: Video sequence'lerinden egzersiz tanÄ±ma

### S17: Neden Dropout kullandÄ±nÄ±z?
**Cevap:**
- Overfitting Ã¶nleme
- Model genelleÅŸtirme yeteneÄŸini artÄ±rÄ±r
- %30 dropout oranÄ± (0.3) standart deÄŸer
- Her hidden layer'da uygulandÄ±
- Validation accuracy'de iyileÅŸme saÄŸladÄ±

### S18: Sequence length neden 60 frame?
**Cevap:**
- Video'larÄ±n ortalama uzunluÄŸuna gÃ¶re seÃ§ildi
- Ã‡ok kÄ±sa: Yeterli bilgi yok
- Ã‡ok uzun: Hesaplama maliyeti artar
- 60 frame â‰ˆ 2-3 saniye (30 FPS'de)
- Deneysel olarak optimal bulundu

---

## ğŸ“ EÄÄ°TÄ°M SÃœRECÄ° HAKKINDA SORULAR

### S19: EÄŸitim parametreleriniz neler?
**Cevap:**
- **Optimizer**: Adam (lr=0.001)
- **Loss**: CrossEntropyLoss
- **Scheduler**: ReduceLROnPlateau (patience=5, factor=0.5)
- **Epoch**: 50
- **Batch Size**: 32 (image), 16 (sequence)
- **Validation Ratio**: 0.2 (%20)

### S20: Neden Adam optimizer seÃ§tiniz?
**Cevap:**
- Adaptive learning rate (her parametre iÃ§in ayrÄ±)
- Momentum ve RMSprop'un birleÅŸimi
- HÄ±zlÄ± yakÄ±nsama
- Standart ve etkili
- PyTorch'ta kolay kullanÄ±m

### S21: Learning rate scheduler neden kullandÄ±nÄ±z?
**Cevap:**
- Validation loss'a gÃ¶re otomatik ayarlama
- Plateau'da takÄ±lmayÄ± Ã¶nler
- Daha iyi sonuÃ§lara ulaÅŸma
- Patience=5: 5 epoch bekle, iyileÅŸme yoksa lr'yi yarÄ±ya indir
- EÄŸitim sÃ¼recini optimize eder

### S22: EÄŸitim ne kadar sÃ¼rdÃ¼?
**Cevap:**
- Image Model: ~2-3 saat (CPU'da)
- Sequence Model: ~3-4 saat (CPU'da)
- GPU kullanÄ±lsaydÄ± daha hÄ±zlÄ± olurdu
- Toplam: ~5-7 saat (her iki model)
- 50 epoch Ã— her epoch ~5-10 dakika

### S23: Overfitting problemi yaÅŸadÄ±nÄ±z mÄ±?
**Cevap:**
- HayÄ±r, Dropout ile Ã¶nlendi
- Train ve validation loss birlikte azaldÄ±
- Validation accuracy dÃ¼zenli arttÄ±
- Early stopping gerekmedi
- Model genelleÅŸtirme yeteneÄŸi iyi

---

## ğŸ“ˆ DEÄERLENDÄ°RME HAKKINDA SORULAR

### S24: Model performansÄ±nÄ±z nasÄ±l?
**Cevap:**
- **Image Model**: Validation accuracy ~91%
- **Sequence Model**: Validation accuracy ~99%
- Sequence Model daha baÅŸarÄ±lÄ± (zaman serisi bilgisi)
- Her iki model de baÅŸarÄ±yla eÄŸitildi
- Confusion matrix ile detaylÄ± analiz yapÄ±ldÄ±

### S25: Hangi metrikleri kullandÄ±nÄ±z?
**Cevap:**
- **Accuracy**: Genel doÄŸruluk oranÄ±
- **Precision**: Pozitif tahminlerin doÄŸruluÄŸu
- **Recall**: GerÃ§ek pozitiflerin tespit oranÄ±
- **F1-Score**: Precision ve Recall'un harmonik ortalamasÄ±
- **Confusion Matrix**: Hangi sÄ±nÄ±flarÄ±n karÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir

### S26: Hangi egzersizler daha zor tanÄ±ndÄ±?
**Cevap:**
- Benzer hareketler karÄ±ÅŸtÄ±rÄ±labiliyor
- Ã–rnek: bench press vs incline bench press
- Confusion matrix'te gÃ¶rÃ¼lebilir
- Daha fazla eÄŸitim verisi ile iyileÅŸtirilebilir
- Model genel olarak iyi performans gÃ¶sterdi

---

## ğŸ”„ GERÃ‡EK KULLANIM HAKKINDA SORULAR

### S27: KullanÄ±cÄ± video yÃ¼klediÄŸinde sistem nasÄ±l Ã§alÄ±ÅŸÄ±yor?
**Cevap:**
1. Video geÃ§ici olarak kaydedilir
2. `pose_detector.process_video()` Ã§aÄŸrÄ±lÄ±r
3. Video frame frame okunur (OpenCV)
4. Her frame'de MediaPipe ile pose detection
5. Her frame'den keypoints Ã§Ä±karÄ±lÄ±r (132 boyut)
6. Keypoints array'i oluÅŸturulur: (frame_count, 132)
7. Sequence length'e gÃ¶re hazÄ±rlanÄ±r (60 frame)
8. Sequence Model'e verilir
9. Tahmin yapÄ±lÄ±r ve sonuÃ§ dÃ¶ndÃ¼rÃ¼lÃ¼r

### S28: Frame'ler gÃ¶rsel dosyasÄ± olarak kaydediliyor mu?
**Cevap:**
- **HayÄ±r**, sadece memory'de iÅŸleniyor
- GÃ¶rsel dosyasÄ± olarak kaydedilmiyor
- Her frame'den direkt keypoints Ã§Ä±karÄ±lÄ±yor
- Daha hÄ±zlÄ± ve verimli
- Disk kullanÄ±mÄ± azalÄ±r

### S29: GerÃ§ek zamanlÄ± iÅŸleme yapÄ±labiliyor mu?
**Cevap:**
- Åu an batch iÅŸleme (video yÃ¼kle â†’ iÅŸle â†’ sonuÃ§)
- GerÃ§ek zamanlÄ± iÃ§in kamera feed'i gerekir
- MediaPipe gerÃ§ek zamanlÄ± destekler
- Gelecek geliÅŸtirme olarak eklenebilir
- Webcam entegrasyonu yapÄ±labilir

---

## ğŸš€ GELECEK GELÄ°ÅTÄ°RMELER HAKKINDA SORULAR

### S30: Projeyi nasÄ±l geliÅŸtirebilirsiniz?
**Cevap:**
- **Veri arttÄ±rma**: Rotation, scale, noise ekleme
- **Ek Ã¶zellikler**: AÃ§Ä± hesaplama, mesafe, hÄ±z
- **Form analizi**: DoÄŸru/yanlÄ±ÅŸ form tespiti
- **Geri bildirim**: KullanÄ±cÄ±ya Ã¶neriler
- **Hibrit model**: Image + Sequence birleÅŸtirme
- **GerÃ§ek zamanlÄ±**: Webcam entegrasyonu
- **Daha fazla egzersiz**: 22'den daha fazla sÄ±nÄ±f

### S31: Form analizi yapÄ±yor musunuz?
**Cevap:**
- Åu an sadece egzersiz tanÄ±ma yapÄ±lÄ±yor
- Form analizi gelecek geliÅŸtirme
- Keypoints'lerden aÃ§Ä± hesaplama yapÄ±labilir
- DoÄŸru/yanlÄ±ÅŸ form karÅŸÄ±laÅŸtÄ±rmasÄ±
- KullanÄ±cÄ±ya geri bildirim sistemi

### S32: Modeli production'a nasÄ±l alÄ±rsÄ±nÄ±z?
**Cevap:**
- Model optimizasyonu (quantization)
- API servisi (FastAPI/Flask)
- Cloud deployment (AWS, GCP, Azure)
- Docker containerization
- Caching ve load balancing
- Monitoring ve logging

---

## ğŸ› TEKNÄ°K SORUNLAR HAKKINDA SORULAR

### S33: Windows'ta MediaPipe ile sorun yaÅŸadÄ±nÄ±z mÄ±?
**Cevap:**
- Evet, TÃ¼rkÃ§e karakter sorunlarÄ±
- Short path kullanarak Ã§Ã¶zÃ¼ldÃ¼
- GPU desteÄŸi kapatÄ±ldÄ± (CPU modu)
- Static mode kullanÄ±ldÄ± (video iÃ§in)
- Ã‡alÄ±ÅŸma zamanÄ±nda dÃ¼zeltildi

### S34: Veri leakage problemi yaÅŸadÄ±nÄ±z mÄ±?
**Cevap:**
- HayÄ±r, dikkatli train/test split yapÄ±ldÄ±
- Test videolarÄ±ndan gÃ¶rsel Ã§Ä±karÄ±lmadÄ±
- AynÄ± videodan hem gÃ¶rsel hem video kullanÄ±lmadÄ± (test'te)
- Random seed ile tekrarlanabilir split
- Validation seti train'den ayrÄ±ldÄ±

### S35: Model eÄŸitimi sÄ±rasÄ±nda hata aldÄ±nÄ±z mÄ±?
**Cevap:**
- Ä°lk baÅŸta sÄ±nÄ±f sayÄ±sÄ± uyumsuzluÄŸu
- GÃ¶rsel ve video sÄ±nÄ±flarÄ± eÅŸleÅŸtirme sorunu
- Label encoder uyumluluÄŸu Ã§Ã¶zÃ¼ldÃ¼
- Ortak sÄ±nÄ±flar filtrelendi
- Kodda dÃ¼zeltmeler yapÄ±ldÄ±

---

## ğŸ“š AKADEMÄ°K/ARAÅTIRMA SORULARI

### S36: LiteratÃ¼rde benzer Ã§alÄ±ÅŸmalar var mÄ±?
**Cevap:**
- Evet, egzersiz tanÄ±ma alanÄ±nda Ã§alÄ±ÅŸmalar mevcut
- MediaPipe kullanan Ã§alÄ±ÅŸmalar var
- LSTM ile video sÄ±nÄ±flandÄ±rma yaygÄ±n
- Bizim yaklaÅŸÄ±mÄ±mÄ±z: Hibrit (gÃ¶rsel + video)
- 22 egzersiz sÄ±nÄ±fÄ± ile kapsamlÄ±

### S37: Projenin bilimsel katkÄ±sÄ± nedir?
**Cevap:**
- Hibrit yaklaÅŸÄ±m (gÃ¶rsel + video)
- MediaPipe keypoints ile egzersiz tanÄ±ma
- Pratik uygulama (kiÅŸisel antrenÃ¶r)
- AÃ§Ä±k kaynak kod ve veri seti
- Tekrarlanabilir metodoloji

### S38: Hangi makine Ã¶ÄŸrenmesi tekniklerini kullandÄ±nÄ±z?
**Cevap:**
- **Supervised Learning**: Etiketli veri ile eÄŸitim
- **Deep Learning**: MLP ve LSTM
- **Transfer Learning**: MediaPipe pre-trained model
- **Time Series Analysis**: LSTM ile sequence analizi
- **Classification**: Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma

---

## ğŸ’¡ PRATÄ°K SORULAR

### S39: Projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in ne gerekli?
**Cevap:**
- Python 3.9+
- PyTorch 2.4.0 (CUDA 12.1 desteÄŸi)
- MediaPipe 0.10.9
- OpenCV, NumPy, scikit-learn
- EÄŸitilmiÅŸ modeller (`models/` klasÃ¶rÃ¼)
- Ä°ÅŸlenmiÅŸ veri (`data/processed/`)

### S40: Kodunuz aÃ§Ä±k kaynak mÄ±?
**Cevap:**
- Evet, GitHub'da paylaÅŸÄ±labilir
- AÃ§Ä±k kaynak lisansÄ± (LICENSE dosyasÄ± var)
- BaÅŸkalarÄ± kullanabilir ve geliÅŸtirebilir
- Akademik kullanÄ±m iÃ§in uygun

---

## ğŸ¯ Ã–ZET CEVAPLAR (HÄ±zlÄ± Referans)

**Proje AmacÄ±**: 22 egzersiz tÃ¼rÃ¼nÃ¼ video/gÃ¶rsellerden otomatik tanÄ±ma

**Teknolojiler**: PyTorch, MediaPipe, OpenCV, LSTM, MLP

**Veri**: Kaggle'dan aÃ§Ä±k kaynak, 22 sÄ±nÄ±f, %70 train / %30 test

**Modeller**: Image Classifier (MLP) + Sequence Classifier (LSTM)

**Performans**: Image ~91%, Sequence ~99% accuracy

**GerÃ§ek KullanÄ±m**: Video yÃ¼kle â†’ Frame frame iÅŸle â†’ Keypoints Ã§Ä±kar â†’ Model tahmin

**Gelecek**: Form analizi, gerÃ§ek zamanlÄ±, daha fazla egzersiz

---

## ğŸ’¬ SUNUM Ä°Ã‡Ä°N Ä°PUÃ‡LARI

1. **GÃ¼venli konuÅŸun**: Projeyi siz yaptÄ±nÄ±z, detaylarÄ± biliyorsunuz
2. **AÃ§Ä±k olun**: BilmediÄŸiniz bir ÅŸey varsa "Bu konuda daha fazla araÅŸtÄ±rma yapabilirim" deyin
3. **Ã–rnekler verin**: Kod Ã¶rnekleri, grafikler, sonuÃ§lar gÃ¶sterin
4. **ZorluklarÄ± anlatÄ±n**: KarÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z sorunlar ve Ã§Ã¶zÃ¼mler
5. **Gelecek planlarÄ±nÄ±zÄ± belirtin**: Projeyi nasÄ±l geliÅŸtireceÄŸiniz

---

**BaÅŸarÄ±lar! ğŸš€**

